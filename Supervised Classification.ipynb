{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classification\n",
    "\n",
    "In the data.csv there are letters (uppercases and lowercases) and numbers, 28x28 pixels in a row format.\n",
    "\n",
    "* First, you need to know which labels are which, meaning you need to visualize some data to realize which number labels represents a letter, or a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "data = pd.read_csv('data_all/data_all.csv', dtype = 'float')\n",
    "#data = np.loadtxt('data_all/data_all.csv', delimiter=',', dtype = 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116322, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(data.iloc[2,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15db75ebe80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARFklEQVR4nO3da4xd1XnG8eedi6+Dx8b3DjY2kxEKAcVQ1xCZm0NNuVQB1IJMk4YoqM4HUBOVVEXkQ1ClSqhqiPop0kTQmJSQpgoIRwoJjkOESYvDYBywsY0vdfBgY5uY8R2PZ+bthzmOJjD73cO57WOv/08anTPnPWv28vE8s/c5a++1zN0F4NzXVHQHANQHYQcSQdiBRBB2IBGEHUhESz03ZmZ89A/UmLvbaI9XtGc3s5vMbJuZ7TCzByv5WQBqy8odZzezZklvSVouqVfSK5Ludvc3gzbs2YEaq8WefYmkHe6+y937Jf1Q0m0V/DwANVRJ2Dsk7RnxfW/psT9iZivNrMfMeirYFoAKVfIB3WiHCh85THf3bkndEofxQJEq2bP3Spo34vsLJO2trDsAaqWSsL8iqcvMFprZOEkrJK2uTrcAVFvZh/HuPmBm90v6uaRmSY+7++aq9QxAVZU99FbWxnjPDtRcTU6qAXD2IOxAIgg7kAjCDiSCsAOJIOxAIup6PXuxRh2N+INx48aH9Vkz55e95YPv9Yb1wcGBsO4+VPa2KzU0FG+7yL7h42HPDiSCsAOJIOxAIgg7kAjCDiSCsAOJSGbobcKEyWF95sx5YX35rSvK3vZvXlob1k+cOBzW84a/KjFw+lRYP3HyaFg/fPhgWI/6zrBdfbFnBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEefM7LLt7TPD+oov/UNYv+zay8L6X91wdWatpSn+m/nO+++H9dMD8SWutXTo+PGwvnNXfHnuhjUbwvqeHf+XWevpeS5se/jwe2E9b5w+79LhcxWzywKJI+xAIgg7kAjCDiSCsAOJIOxAIgg7kIhz5nr28eMnhfXORZ1hfVbHjLD+9nvZY77jW1vDth3TpoX1cS3xf4NZPA12NM7flNP2VM4Y/8Vz54b1zosuCOvbt7+dWWtqag7bbt36clg/3f9BWD9wMHvb/f3xdfzSubfgcEVhN7Pdko5KGpQ04O6Lq9EpANVXjT37MnePT3UCUDjeswOJqDTsLul5M3vVzFaO9gQzW2lmPWbWU+G2AFSg0sP4pe6+18xmSVpjZlvd/cWRT3D3bkndUm0vhAEQq2jP7u57S7cHJD0jaUk1OgWg+soOu5lNNrPzztyXdKOkTdXqGIDqKvt6djO7SMN7c2n47cAP3P1fctrU7DC+pWVcWJ8ze0FYb26Jx8qbm7Pf8Uya1B62vfLa5WF9cns8p33b1Lawft3NV2XW2idNDNtOzFmqun1i3H7WlClhPXLgyJGwvv9wPJ/+748dC+uPfv3RzNprr/0i/tm/3xvWG1nW9exlv2d3912SPl12jwDUFUNvQCIIO5AIwg4kgrADiSDsQCLOmamkG1k0bDcWecOKM2dkX2ba0hoPrbW1xZffdnR0hfUrlsXnUc3/5PzM2ueuuTJsO2fq1LA+mLOUdfezP8us/aT7mcyaJD3//H+E9UZebpqppIHEEXYgEYQdSARhBxJB2IFEEHYgEYQdSMQ5M5V0I6t06eC89vve3VX2z84bw9+7d3u87X07w3pn5+WZtQUL/iRsO7s9vnS4OWep7Is6s88/6FiYPf4v5U/fXcfTU6qGPTuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4lgnP0cMBRc192UMxadN4Z/8mQ8XfOc2QvD+oJLF2TW5k+fHrY9dfp0WM+bSnrjb97MrP1u+46wbT3neagX9uxAIgg7kAjCDiSCsAOJIOxAIgg7kAjCDiSCcfazQN688+3tMzNrkyaeF7YdNz5eknny5Hju9uWfvzmsX/Fnl2TWFsyYEbbtO3EirK/bui2sv/Dfz2fWtm1dH7Zt5Hnhy5W7Zzezx83sgJltGvHY+Wa2xsy2l27jlQYAFG4sh/Hfk3TThx57UNJad++StLb0PYAGlht2d39R0qEPPXybpFWl+6sk3V7lfgGosnLfs892932S5O77zGxW1hPNbKWklWVuB0CV1PwDOnfvltQtpbuwI9AIyh16229mcyWpdHugel0CUAvlhn21pHtK9++R9Gx1ugOgVnIP483sKUnXS5phZr2SvinpEUk/MrN7Jb0t6c5advJsZxb/TZ0yJb6u+4677gvrS27NXiO986LsudMlaXpbW1hvbYl/RTpnZY/xS9KE1ux56fPmfd91MD5g3Lp+S1h/+eXVmbXjxw+Hbc9FuWF397szSjdUuS8AaojTZYFEEHYgEYQdSARhBxJB2IFEcIlrHeRN5zx1aubZxpKkLz+wIqxf9YlPZNbyhrfyDAbTVEvSu319Yf3wyYOZtfaJk8K286fHl8D+9Z03hvVD776fWXvt1/8Ttl2//idhvdJluIvAnh1IBGEHEkHYgUQQdiARhB1IBGEHEkHYgUQwzt4ABgfipYmPnjwZ1gcGBzNr0XLOknRqIB4vPpSzLPLP/vfVsP7O9ncyax1dHWHbv/jMFWF9bnt7WF9253WZtZbW5rDtW2+9EtaPHHkvrPf3fxDWi8CeHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRJh7/RZpYUWY0Y0bNyGsX3NNPFP3JYsXZdaami1se6zveFjv3bk7rPf0PBfWjx8/kllra4uXg75h+efj+hc+G9ZXfPbazFrf8fjf/Z9PZy/3LElr/yv+d//yl0+G9VouCe3uo/6ns2cHEkHYgUQQdiARhB1IBGEHEkHYgUQQdiARXM/eAPr7T4X1DRvWhPWdOzeWve2B0/G2T5w8Gtb7+uJllYeGsq+17++Pr9N/Y+O6sD5n4eywPnDd0szarClTwraLllwS1nf9dldYb/pVvB8dHKzdOHuW3D27mT1uZgfMbNOIxx42s3fMbGPp65badhNApcZyGP89STeN8vi33X1R6eun1e0WgGrLDbu7vyjpUB36AqCGKvmA7n4ze710mD8t60lmttLMesysp4JtAahQuWH/jqROSYsk7ZP0rawnunu3uy9298VlbgtAFZQVdnff7+6DPnzpznclLalutwBUW1lhN7O5I769Q9KmrOcCaAy54+xm9pSk6yXNMLNeSd+UdL2ZLZLkknZL+koN+5iA+DL/999/t6J6o4rG4CVpx84NYf3IE/HnxgsuXZhZW7Y0npP+ko54TvveW+OD2Z+v7grre/ZsCeu1kBt2d797lIcfq0FfANQQp8sCiSDsQCIIO5AIwg4kgrADiWAqaZzF4mmyL7sseyrpz33xC2Hbb/z9F8P6B6fjZba//o+PhvVV3f+cWRscjJfRzsNU0kDiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJIKppM8CTU3NYT06V6KWSwMXLz5t4/jxvuza4XjJ5iaLx/AntLaG9clTJof1IrBnBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYyz18G0aXPC+qxZ88P60mW3hvU3N2ZPubxt2/qw7dk6DXXR8sbhm5rjehHYswOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kAjG2avALP6befHFV4b1K65eGtZv/ps/D+sTfjAxs3b48IGw7dGj8bLHjXw9fN7r3tY2LbM2ub2y682HctZbqONyDGOWu2c3s3lm9oKZbTGzzWb21dLj55vZGjPbXrrNfmUBFG4sh/EDkh5w909KukrSfWZ2iaQHJa119y5Ja0vfA2hQuWF3933uvqF0/6ikLZI6JN0maVXpaask3V6rTgKo3Md6z25mCyRdLmm9pNnuvk8a/oNgZrMy2qyUtLKybgKo1JjDbmZtkn4s6WvufsRyLgQ4w927JXWXfkYDfmwBpGFMQ29m1qrhoD/p7k+XHt5vZnNL9bmS4o99ARQqd89uw7vwxyRtcfeR69CulnSPpEdKt8/WpIdngaam+G/mn15zdVi/68t/GdY/09UV1ufPmJFZu/yGy8O2m3+9Oaz7UAMPveW87p9a+qnM2lWXXhz/7Jwj1/192dNUS9K2DfHrOlTA6zqWw/ilkv5W0htmtrH02EMaDvmPzOxeSW9LurM2XQRQDblhd/eXlL3q/Q3V7Q6AWuF0WSARhB1IBGEHEkHYgUQQdiARXOJaBXljpq+ueymsR0suS5LnjMN/+sILM2udy+Ix/qHr43qe5pzx6Gi8Om865kqN9SzP0byxZ09Yf+HFnrDe0/NcWC/i0mH27EAiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJIJx9irIGzPNXzZ5X1hvHRf/N51akT3VdPuk7GmmJak5ZzrmPDOnTAnr0yZnT9k8vqW2v34fnD6dWTt07FjYNm8cfd3T68J63hTdRWDPDiSCsAOJIOxAIgg7kAjCDiSCsAOJIOxAIizvWuqqbowVYcoyflw8Vj5z5rzMWkvr+Iq2nTcnflfX4rB+QeeCzFrb1MqWTc5zrO94Zq135+6wbd716Hnj6P39H4T1WnL3US/kZ88OJIKwA4kg7EAiCDuQCMIOJIKwA4kg7EAicsfZzWyepCckzZE0JKnb3f/dzB6W9HeSDpae+pC7/zTnZzHOXgPNzbW7LtxyrnefMmV6WJ808bzMWqXnAOQZOH0qs3bi5NGwbV/fgbA+NDRYVp/qIWucfSy/JQOSHnD3DWZ2nqRXzWxNqfZtd/+3anUSQO2MZX32fZL2le4fNbMtkjpq3TEA1fWx3rOb2QJJl0s6M8/S/Wb2upk9bmbTMtqsNLMeM4vn+QFQU2MOu5m1SfqxpK+5+xFJ35HUKWmRhvf83xqtnbt3u/tid49PogZQU2MKu5m1ajjoT7r705Lk7vvdfdCHZ1v8rqQltesmgErlht2Gl8J8TNIWd390xONzRzztDkmbqt89ANUylqG3qyWtk/SGhofeJOkhSXdr+BDeJe2W9JXSh3nRz2LoDaixrKE3rmcHzjFczw4kjrADiSDsQCIIO5AIwg4kgrADiSDsQCIIO5AIwg4kgrADiSDsQCIIO5AIwg4kgrADiajdHMSje0/S70Z8P6P0WCNq1L41ar8k+lauavbtwqxCXa9n/8jGzXoadW66Ru1bo/ZLom/lqlffOIwHEkHYgUQUHfbugrcfadS+NWq/JPpWrrr0rdD37ADqp+g9O4A6IexAIgoJu5ndZGbbzGyHmT1YRB+ymNluM3vDzDYWvT5daQ29A2a2acRj55vZGjPbXroddY29gvr2sJm9U3rtNprZLQX1bZ6ZvWBmW8xss5l9tfR4oa9d0K+6vG51f89uZs2S3pK0XFKvpFck3e3ub9a1IxnMbLekxe5e+AkYZnatpGOSnnD3S0uP/aukQ+7+SOkP5TR3/6cG6dvDko4VvYx3abWiuSOXGZd0u6QvqcDXLujXXarD61bEnn2JpB3uvsvd+yX9UNJtBfSj4bn7i5IOfejh2yStKt1fpeFflrrL6FtDcPd97r6hdP+opDPLjBf62gX9qosiwt4hac+I73vVWOu9u6TnzexVM1tZdGdGMfvMMlul21kF9+fDcpfxrqcPLTPeMK9dOcufV6qIsI+2NE0jjf8tdfcrJN0s6b7S4SrGZkzLeNfLKMuMN4Rylz+vVBFh75U0b8T3F0jaW0A/RuXue0u3ByQ9o8Zbinr/mRV0S7cHCu7PHzTSMt6jLTOuBnjtilz+vIiwvyKpy8wWmtk4SSskrS6gHx9hZpNLH5zIzCZLulGNtxT1akn3lO7fI+nZAvvyRxplGe+sZcZV8GtX+PLn7l73L0m3aPgT+Z2SvlFEHzL6dZGk35a+NhfdN0lPafiw7rSGj4julTRd0lpJ20u35zdQ376v4aW9X9dwsOYW1LerNfzW8HVJG0tftxT92gX9qsvrxumyQCI4gw5IBGEHEkHYgUQQdiARhB1IBGEHEkHYgUT8P2QMPyrrT8CBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "fig, ax = plt.subplots()\n",
    "#ax.imshow(image.reshape(28, 28), cmap=plt.cm.bone, interpolation='nearest') \n",
    "ax.imshow(image.reshape(28, 28), cmap=plt.cm.bone) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15dbd976700>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(data.iloc[34,1:])\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image.reshape(28, 28), cmap=plt.cm.bone) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[34,0]\n",
    "#data[data['e'] == '38.0']\n",
    "#e translates into the number 0-9, then capital letters, then lower-case letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def letter_mapping(e_num):\n",
    "    \"\"\"\n",
    "    Converts number from e_column into corresponding letter or number\n",
    "    :param  e_num from sequence 0-9, then capital letters, then lower-case letters\n",
    "    returns corresponding actual letter\n",
    "    \"\"\"\n",
    "    if e_num < 10:\n",
    "        return str(e_num)\n",
    "    elif e_num < 36:\n",
    "        return chr(int(e_num - 10 + 65))\n",
    "    else:\n",
    "        return chr(int(e_num - 36 + 97))\n",
    "\n",
    "letter_mapping(38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uppercase Letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, try to train a classifier model to predict the uppercases. Use every single model you know for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upper_case = data[(data['e'] > 9) & (data['e'] < 36)]\n",
    "\n",
    "X = df_upper_case.drop(columns = ['e'])\n",
    "y = df_upper_case['e']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_neighbors = 5\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = classifier.predict(X_train)\n",
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.92      0.93      0.93       846\n",
      "           B       0.99      0.76      0.86       522\n",
      "           C       0.87      0.97      0.92      1379\n",
      "           D       0.94      0.72      0.81       628\n",
      "           E       0.98      0.87      0.92       693\n",
      "           F       0.90      0.89      0.89      1158\n",
      "           G       0.99      0.78      0.87       359\n",
      "           H       0.92      0.86      0.89       416\n",
      "           I       0.84      0.98      0.91      1630\n",
      "           J       0.91      0.82      0.86       497\n",
      "           K       0.95      0.80      0.87       309\n",
      "           L       0.88      0.94      0.91       646\n",
      "           M       0.98      0.96      0.97      1194\n",
      "           N       0.90      0.95      0.93      1064\n",
      "           O       0.90      0.99      0.94      3374\n",
      "           P       0.86      0.92      0.89      1108\n",
      "           Q       0.99      0.57      0.72       328\n",
      "           R       0.97      0.75      0.85       661\n",
      "           S       0.97      0.99      0.98      2770\n",
      "           T       0.91      0.97      0.94      1269\n",
      "           U       0.92      0.94      0.93      1590\n",
      "           V       0.87      0.89      0.88       645\n",
      "           W       0.99      0.87      0.93       642\n",
      "           X       0.97      0.79      0.87       350\n",
      "           Y       0.91      0.82      0.87       633\n",
      "           Z       0.97      0.88      0.93       365\n",
      "\n",
      "    accuracy                           0.92     25076\n",
      "   macro avg       0.93      0.87      0.89     25076\n",
      "weighted avg       0.92      0.92      0.92     25076\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Test dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.89      0.88      0.89       216\n",
      "           B       0.95      0.56      0.71       126\n",
      "           C       0.84      0.96      0.89       360\n",
      "           D       0.95      0.66      0.78       151\n",
      "           E       0.93      0.80      0.86       158\n",
      "           F       0.84      0.83      0.84       282\n",
      "           G       0.97      0.64      0.77        88\n",
      "           H       0.76      0.78      0.77       105\n",
      "           I       0.76      0.96      0.85       417\n",
      "           J       0.85      0.77      0.81       129\n",
      "           K       0.91      0.68      0.78        73\n",
      "           L       0.83      0.89      0.86       164\n",
      "           M       0.97      0.95      0.96       291\n",
      "           N       0.87      0.89      0.88       287\n",
      "           O       0.86      0.98      0.91       782\n",
      "           P       0.83      0.88      0.85       289\n",
      "           Q       0.97      0.34      0.50        85\n",
      "           R       0.92      0.64      0.75       148\n",
      "           S       0.97      0.98      0.97       738\n",
      "           T       0.88      0.98      0.93       307\n",
      "           U       0.89      0.93      0.91       412\n",
      "           V       0.80      0.88      0.84       151\n",
      "           W       0.98      0.80      0.88       164\n",
      "           X       0.97      0.74      0.84        82\n",
      "           Y       0.87      0.76      0.81       165\n",
      "           Z       0.96      0.81      0.88        99\n",
      "\n",
      "    accuracy                           0.88      6269\n",
      "   macro avg       0.89      0.81      0.84      6269\n",
      "weighted avg       0.89      0.88      0.87      6269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = np.sort(y.unique())\n",
    "class_names = list(map(letter_mapping, labels))\n",
    "\n",
    "print('\\n')\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Training dataset\\n')\n",
    "print(classification_report(y_train, y_pred_train, labels = labels, target_names = class_names))\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Test dataset\\n')\n",
    "print(classification_report(y_test,y_pred_test, labels = labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'random_state':0,'max_depth':4}\n",
    "classifier = DecisionTreeClassifier(**params)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = classifier.predict(X_train)\n",
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.32      0.43      0.37       846\n",
      "           B       0.00      0.00      0.00       522\n",
      "           C       0.48      0.61      0.54      1379\n",
      "           D       0.28      0.24      0.26       628\n",
      "           E       0.15      0.43      0.22       693\n",
      "           F       0.42      0.22      0.29      1158\n",
      "           G       0.00      0.00      0.00       359\n",
      "           H       0.00      0.00      0.00       416\n",
      "           I       0.32      0.92      0.48      1630\n",
      "           J       0.00      0.00      0.00       497\n",
      "           K       0.00      0.00      0.00       309\n",
      "           L       0.00      0.00      0.00       646\n",
      "           M       0.50      0.61      0.55      1194\n",
      "           N       0.37      0.65      0.47      1064\n",
      "           O       0.79      0.81      0.80      3374\n",
      "           P       0.00      0.00      0.00      1108\n",
      "           Q       0.00      0.00      0.00       328\n",
      "           R       0.00      0.00      0.00       661\n",
      "           S       0.43      0.74      0.55      2770\n",
      "           T       0.61      0.55      0.58      1269\n",
      "           U       0.50      0.57      0.53      1590\n",
      "           V       0.00      0.00      0.00       645\n",
      "           W       0.00      0.00      0.00       642\n",
      "           X       0.00      0.00      0.00       350\n",
      "           Y       0.00      0.00      0.00       633\n",
      "           Z       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.45     25076\n",
      "   macro avg       0.20      0.26      0.22     25076\n",
      "weighted avg       0.35      0.45      0.38     25076\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Test dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.32      0.38      0.35       216\n",
      "           B       0.00      0.00      0.00       126\n",
      "           C       0.51      0.65      0.58       360\n",
      "           D       0.28      0.25      0.26       151\n",
      "           E       0.14      0.42      0.21       158\n",
      "           F       0.36      0.19      0.25       282\n",
      "           G       0.00      0.00      0.00        88\n",
      "           H       0.00      0.00      0.00       105\n",
      "           I       0.31      0.89      0.46       417\n",
      "           J       0.00      0.00      0.00       129\n",
      "           K       0.00      0.00      0.00        73\n",
      "           L       0.00      0.00      0.00       164\n",
      "           M       0.50      0.60      0.55       291\n",
      "           N       0.39      0.61      0.48       287\n",
      "           O       0.78      0.78      0.78       782\n",
      "           P       0.00      0.00      0.00       289\n",
      "           Q       0.00      0.00      0.00        85\n",
      "           R       0.00      0.00      0.00       148\n",
      "           S       0.44      0.73      0.55       738\n",
      "           T       0.60      0.61      0.60       307\n",
      "           U       0.54      0.61      0.57       412\n",
      "           V       0.00      0.00      0.00       151\n",
      "           W       0.00      0.00      0.00       164\n",
      "           X       0.00      0.00      0.00        82\n",
      "           Y       0.00      0.00      0.00       165\n",
      "           Z       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.44      6269\n",
      "   macro avg       0.20      0.26      0.22      6269\n",
      "weighted avg       0.34      0.44      0.38      6269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Training dataset\\n')\n",
    "print(classification_report(y_train, y_pred_train, labels = labels, target_names = class_names))\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Test dataset\\n')\n",
    "print(classification_report(y_test,y_pred_test, labels = labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= RandomForestClassifier(n_estimators=100,max_depth=4, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.68      0.39      0.49       846\n",
      "           B       0.00      0.00      0.00       522\n",
      "           C       0.48      0.78      0.60      1379\n",
      "           D       0.00      0.00      0.00       628\n",
      "           E       0.00      0.00      0.00       693\n",
      "           F       0.61      0.32      0.42      1158\n",
      "           G       0.00      0.00      0.00       359\n",
      "           H       0.00      0.00      0.00       416\n",
      "           I       0.44      0.91      0.59      1630\n",
      "           J       0.00      0.00      0.00       497\n",
      "           K       0.00      0.00      0.00       309\n",
      "           L       0.93      0.04      0.08       646\n",
      "           M       0.65      0.92      0.76      1194\n",
      "           N       0.53      0.58      0.55      1064\n",
      "           O       0.61      0.95      0.74      3374\n",
      "           P       0.64      0.74      0.68      1108\n",
      "           Q       0.00      0.00      0.00       328\n",
      "           R       0.80      0.18      0.30       661\n",
      "           S       0.49      0.88      0.63      2770\n",
      "           T       0.64      0.82      0.72      1269\n",
      "           U       0.57      0.73      0.64      1590\n",
      "           V       0.88      0.18      0.29       645\n",
      "           W       1.00      0.04      0.08       642\n",
      "           X       0.00      0.00      0.00       350\n",
      "           Y       0.00      0.00      0.00       633\n",
      "           Z       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.56     25076\n",
      "   macro avg       0.38      0.33      0.29     25076\n",
      "weighted avg       0.49      0.56      0.46     25076\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Test dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.73      0.38      0.50       216\n",
      "           B       0.00      0.00      0.00       126\n",
      "           C       0.52      0.83      0.64       360\n",
      "           D       0.00      0.00      0.00       151\n",
      "           E       0.00      0.00      0.00       158\n",
      "           F       0.60      0.34      0.43       282\n",
      "           G       0.00      0.00      0.00        88\n",
      "           H       0.00      0.00      0.00       105\n",
      "           I       0.41      0.88      0.56       417\n",
      "           J       0.00      0.00      0.00       129\n",
      "           K       0.00      0.00      0.00        73\n",
      "           L       0.86      0.04      0.07       164\n",
      "           M       0.63      0.91      0.74       291\n",
      "           N       0.58      0.57      0.58       287\n",
      "           O       0.61      0.95      0.74       782\n",
      "           P       0.61      0.69      0.65       289\n",
      "           Q       0.00      0.00      0.00        85\n",
      "           R       0.73      0.15      0.25       148\n",
      "           S       0.51      0.86      0.64       738\n",
      "           T       0.63      0.86      0.73       307\n",
      "           U       0.59      0.75      0.66       412\n",
      "           V       0.94      0.21      0.35       151\n",
      "           W       1.00      0.04      0.07       164\n",
      "           X       0.00      0.00      0.00        82\n",
      "           Y       0.00      0.00      0.00       165\n",
      "           Z       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.56      6269\n",
      "   macro avg       0.38      0.33      0.29      6269\n",
      "weighted avg       0.49      0.56      0.47      6269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print('\\n')\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Training dataset\\n')\n",
    "print(classification_report(y_train, y_pred_train, labels = labels, target_names = class_names))\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Test dataset\\n')\n",
    "print(classification_report(y_test,y_pred_test, labels = labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0,max_iter=4000))\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       846\n",
      "           B       1.00      1.00      1.00       522\n",
      "           C       1.00      1.00      1.00      1379\n",
      "           D       1.00      1.00      1.00       628\n",
      "           E       1.00      1.00      1.00       693\n",
      "           F       0.99      1.00      1.00      1158\n",
      "           G       1.00      1.00      1.00       359\n",
      "           H       1.00      1.00      1.00       416\n",
      "           I       1.00      1.00      1.00      1630\n",
      "           J       0.99      1.00      1.00       497\n",
      "           K       1.00      1.00      1.00       309\n",
      "           L       1.00      1.00      1.00       646\n",
      "           M       1.00      1.00      1.00      1194\n",
      "           N       1.00      1.00      1.00      1064\n",
      "           O       1.00      1.00      1.00      3374\n",
      "           P       1.00      0.99      1.00      1108\n",
      "           Q       1.00      1.00      1.00       328\n",
      "           R       1.00      1.00      1.00       661\n",
      "           S       1.00      1.00      1.00      2770\n",
      "           T       1.00      1.00      1.00      1269\n",
      "           U       1.00      1.00      1.00      1590\n",
      "           V       1.00      1.00      1.00       645\n",
      "           W       1.00      1.00      1.00       642\n",
      "           X       1.00      0.99      1.00       350\n",
      "           Y       1.00      1.00      1.00       633\n",
      "           Z       1.00      1.00      1.00       365\n",
      "\n",
      "    accuracy                           1.00     25076\n",
      "   macro avg       1.00      1.00      1.00     25076\n",
      "weighted avg       1.00      1.00      1.00     25076\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Test dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      0.75      0.75       216\n",
      "           B       0.74      0.77      0.75       126\n",
      "           C       0.84      0.85      0.85       360\n",
      "           D       0.80      0.77      0.78       151\n",
      "           E       0.76      0.72      0.74       158\n",
      "           F       0.70      0.80      0.75       282\n",
      "           G       0.77      0.69      0.73        88\n",
      "           H       0.74      0.63      0.68       105\n",
      "           I       0.86      0.90      0.88       417\n",
      "           J       0.67      0.71      0.69       129\n",
      "           K       0.73      0.60      0.66        73\n",
      "           L       0.92      0.91      0.92       164\n",
      "           M       0.90      0.88      0.89       291\n",
      "           N       0.79      0.77      0.78       287\n",
      "           O       0.93      0.92      0.92       782\n",
      "           P       0.87      0.81      0.84       289\n",
      "           Q       0.71      0.62      0.66        85\n",
      "           R       0.69      0.66      0.67       148\n",
      "           S       0.91      0.91      0.91       738\n",
      "           T       0.89      0.96      0.92       307\n",
      "           U       0.81      0.86      0.83       412\n",
      "           V       0.71      0.76      0.74       151\n",
      "           W       0.86      0.77      0.81       164\n",
      "           X       0.81      0.62      0.70        82\n",
      "           Y       0.72      0.76      0.74       165\n",
      "           Z       0.81      0.77      0.79        99\n",
      "\n",
      "    accuracy                           0.83      6269\n",
      "   macro avg       0.80      0.78      0.78      6269\n",
      "weighted avg       0.83      0.83      0.83      6269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print('\\n')\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Training dataset\\n')\n",
    "print(classification_report(y_train, y_pred_train, labels = labels, target_names = class_names))\n",
    "print('\\n'+\"*\"*40)\n",
    "print('\\n Classifier performance on Test dataset\\n')\n",
    "print(classification_report(y_test,y_pred_test, labels = labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowercase Letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with lowercases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lower_case = data[data['e'] > 35]\n",
    "\n",
    "X = df_lower_case.drop(columns = ['e'])\n",
    "y = df_lower_case['e']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "labels = np.sort(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "def print_classification_report(y_true, y_pred, labels, desc):\n",
    "    \"\"\"\n",
    "    Print classification report\n",
    "    returns None\n",
    "    \"\"\"\n",
    "    class_names = list(map(letter_mapping, labels))\n",
    "    print('\\n'+\"*\"*40)\n",
    "    print(f'\\n Classifier performance on {desc} dataset\\n')\n",
    "    report = classification_report(y_true, y_pred, labels = labels, target_names = class_names)\n",
    "    print(report)\n",
    "    \n",
    "# Convergence warning is taking up too much space in my output, so I'm ignoring it now\n",
    "@ignore_warnings(category = ConvergenceWarning)\n",
    "def run_classifier(classifier_func, X_train, X_test, y_train, y_test, labels):\n",
    "    \"\"\"\n",
    "    Takes classifier function, gets predictions for train/test sets and prints reports\n",
    "    by calling an additional function.\n",
    "    \n",
    "    returns None\n",
    "    \"\"\"\n",
    "    classifier_func.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred_train = classifier_func.predict(X_train)\n",
    "    print_classification_report(y_train, y_pred_train, labels, \"Training\")\n",
    "    \n",
    "    y_pred_test = classifier_func.predict(X_test)\n",
    "    print_classification_report(y_test, y_pred_test, labels, \"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.88      0.92      0.90      1331\n",
      "           b       0.95      0.90      0.92       689\n",
      "           c       0.87      0.83      0.85       354\n",
      "           d       0.96      0.94      0.95      1324\n",
      "           e       0.95      0.99      0.97      3255\n",
      "           f       0.95      0.66      0.78       321\n",
      "           g       0.86      0.63      0.73       473\n",
      "           h       0.90      0.92      0.91      1178\n",
      "           i       0.71      0.47      0.57       342\n",
      "           j       0.87      0.78      0.82       261\n",
      "           k       0.96      0.72      0.82       371\n",
      "           l       0.78      0.98      0.87      2001\n",
      "           m       0.98      0.94      0.96       368\n",
      "           n       0.93      0.96      0.94      1524\n",
      "           o       0.85      0.93      0.89       366\n",
      "           p       0.89      0.84      0.86       304\n",
      "           q       0.78      0.67      0.72       404\n",
      "           r       0.91      0.97      0.94      1840\n",
      "           s       0.94      0.91      0.92       339\n",
      "           t       0.94      0.90      0.92      2401\n",
      "           u       0.88      0.85      0.87       387\n",
      "           v       0.82      0.87      0.85       374\n",
      "           w       0.97      0.93      0.95       391\n",
      "           x       0.95      0.83      0.89       381\n",
      "           y       0.88      0.69      0.77       303\n",
      "           z       0.98      0.85      0.91       365\n",
      "\n",
      "    accuracy                           0.90     21647\n",
      "   macro avg       0.90      0.84      0.86     21647\n",
      "weighted avg       0.91      0.90      0.90     21647\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.84      0.84      0.84       313\n",
      "           b       0.92      0.80      0.85       164\n",
      "           c       0.79      0.71      0.74        78\n",
      "           d       0.93      0.91      0.92       359\n",
      "           e       0.93      0.98      0.96       837\n",
      "           f       0.87      0.42      0.56        79\n",
      "           g       0.75      0.41      0.53       116\n",
      "           h       0.86      0.88      0.87       301\n",
      "           i       0.52      0.34      0.41        85\n",
      "           j       0.67      0.68      0.67        56\n",
      "           k       0.96      0.53      0.68        95\n",
      "           l       0.73      0.96      0.83       534\n",
      "           m       0.92      0.88      0.90        96\n",
      "           n       0.89      0.93      0.91       374\n",
      "           o       0.81      0.91      0.85       100\n",
      "           p       0.82      0.78      0.80        64\n",
      "           q       0.64      0.55      0.59       101\n",
      "           r       0.87      0.95      0.91       480\n",
      "           s       0.94      0.92      0.93        98\n",
      "           t       0.92      0.84      0.88       564\n",
      "           u       0.85      0.77      0.81        95\n",
      "           v       0.79      0.94      0.86        94\n",
      "           w       0.91      0.97      0.94        76\n",
      "           x       0.88      0.75      0.81        89\n",
      "           y       0.91      0.64      0.75        78\n",
      "           z       0.95      0.91      0.93        86\n",
      "\n",
      "    accuracy                           0.86      5412\n",
      "   macro avg       0.84      0.78      0.80      5412\n",
      "weighted avg       0.86      0.86      0.85      5412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K neighbor\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       1.00      0.99      0.99      1331\n",
      "           b       1.00      1.00      1.00       689\n",
      "           c       1.00      1.00      1.00       354\n",
      "           d       1.00      1.00      1.00      1324\n",
      "           e       0.99      1.00      1.00      3255\n",
      "           f       0.99      1.00      1.00       321\n",
      "           g       0.99      1.00      0.99       473\n",
      "           h       1.00      1.00      1.00      1178\n",
      "           i       0.92      0.52      0.66       342\n",
      "           j       1.00      1.00      1.00       261\n",
      "           k       0.99      1.00      0.99       371\n",
      "           l       0.93      0.99      0.96      2001\n",
      "           m       1.00      1.00      1.00       368\n",
      "           n       1.00      1.00      1.00      1524\n",
      "           o       1.00      1.00      1.00       366\n",
      "           p       1.00      1.00      1.00       304\n",
      "           q       1.00      0.99      1.00       404\n",
      "           r       1.00      0.99      0.99      1840\n",
      "           s       1.00      1.00      1.00       339\n",
      "           t       0.99      1.00      0.99      2401\n",
      "           u       0.99      1.00      1.00       387\n",
      "           v       1.00      1.00      1.00       374\n",
      "           w       1.00      1.00      1.00       391\n",
      "           x       0.99      0.99      0.99       381\n",
      "           y       1.00      1.00      1.00       303\n",
      "           z       1.00      1.00      1.00       365\n",
      "\n",
      "    accuracy                           0.99     21647\n",
      "   macro avg       0.99      0.98      0.98     21647\n",
      "weighted avg       0.99      0.99      0.99     21647\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.76      0.75      0.76       313\n",
      "           b       0.86      0.76      0.81       164\n",
      "           c       0.64      0.72      0.68        78\n",
      "           d       0.87      0.90      0.88       359\n",
      "           e       0.90      0.89      0.89       837\n",
      "           f       0.70      0.65      0.67        79\n",
      "           g       0.51      0.47      0.49       116\n",
      "           h       0.78      0.84      0.81       301\n",
      "           i       0.43      0.28      0.34        85\n",
      "           j       0.56      0.68      0.61        56\n",
      "           k       0.70      0.55      0.62        95\n",
      "           l       0.83      0.90      0.86       534\n",
      "           m       0.90      0.73      0.80        96\n",
      "           n       0.81      0.85      0.83       374\n",
      "           o       0.84      0.78      0.81       100\n",
      "           p       0.72      0.69      0.70        64\n",
      "           q       0.49      0.41      0.44       101\n",
      "           r       0.88      0.89      0.88       480\n",
      "           s       0.86      0.76      0.80        98\n",
      "           t       0.77      0.80      0.78       564\n",
      "           u       0.84      0.78      0.81        95\n",
      "           v       0.76      0.83      0.79        94\n",
      "           w       0.85      0.96      0.90        76\n",
      "           x       0.62      0.53      0.57        89\n",
      "           y       0.58      0.69      0.63        78\n",
      "           z       0.76      0.72      0.74        86\n",
      "\n",
      "    accuracy                           0.80      5412\n",
      "   macro avg       0.74      0.72      0.73      5412\n",
      "weighted avg       0.80      0.80      0.80      5412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OnevsOne\n",
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0,max_iter=4000))\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.50      0.42      0.46      1331\n",
      "           b       0.81      0.33      0.47       689\n",
      "           c       0.00      0.00      0.00       354\n",
      "           d       0.61      0.78      0.68      1324\n",
      "           e       0.51      0.93      0.66      3255\n",
      "           f       0.00      0.00      0.00       321\n",
      "           g       0.00      0.00      0.00       473\n",
      "           h       0.54      0.66      0.59      1178\n",
      "           i       0.00      0.00      0.00       342\n",
      "           j       0.00      0.00      0.00       261\n",
      "           k       0.00      0.00      0.00       371\n",
      "           l       0.61      0.94      0.74      2001\n",
      "           m       1.00      0.01      0.02       368\n",
      "           n       0.66      0.83      0.74      1524\n",
      "           o       0.00      0.00      0.00       366\n",
      "           p       0.00      0.00      0.00       304\n",
      "           q       0.00      0.00      0.00       404\n",
      "           r       0.63      0.88      0.73      1840\n",
      "           s       0.88      0.04      0.08       339\n",
      "           t       0.51      0.75      0.61      2401\n",
      "           u       0.00      0.00      0.00       387\n",
      "           v       0.00      0.00      0.00       374\n",
      "           w       1.00      0.05      0.09       391\n",
      "           x       0.00      0.00      0.00       381\n",
      "           y       0.00      0.00      0.00       303\n",
      "           z       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.57     21647\n",
      "   macro avg       0.32      0.25      0.23     21647\n",
      "weighted avg       0.46      0.57      0.47     21647\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.49      0.36      0.42       313\n",
      "           b       0.72      0.31      0.43       164\n",
      "           c       0.00      0.00      0.00        78\n",
      "           d       0.62      0.76      0.68       359\n",
      "           e       0.51      0.95      0.66       837\n",
      "           f       0.00      0.00      0.00        79\n",
      "           g       0.00      0.00      0.00       116\n",
      "           h       0.56      0.62      0.59       301\n",
      "           i       0.00      0.00      0.00        85\n",
      "           j       0.00      0.00      0.00        56\n",
      "           k       0.00      0.00      0.00        95\n",
      "           l       0.62      0.94      0.75       534\n",
      "           m       1.00      0.02      0.04        96\n",
      "           n       0.63      0.78      0.70       374\n",
      "           o       0.00      0.00      0.00       100\n",
      "           p       0.00      0.00      0.00        64\n",
      "           q       0.00      0.00      0.00       101\n",
      "           r       0.64      0.88      0.74       480\n",
      "           s       1.00      0.03      0.06        98\n",
      "           t       0.50      0.76      0.60       564\n",
      "           u       0.00      0.00      0.00        95\n",
      "           v       0.00      0.00      0.00        94\n",
      "           w       1.00      0.01      0.03        76\n",
      "           x       0.00      0.00      0.00        89\n",
      "           y       0.00      0.00      0.00        78\n",
      "           z       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.57      5412\n",
      "   macro avg       0.32      0.25      0.22      5412\n",
      "weighted avg       0.47      0.57      0.47      5412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "classifier= RandomForestClassifier(n_estimators=100,max_depth=4, random_state=0)\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.39      0.70      0.50      1331\n",
      "           b       0.25      0.45      0.32       689\n",
      "           c       0.00      0.00      0.00       354\n",
      "           d       0.35      0.67      0.46      1324\n",
      "           e       0.67      0.84      0.75      3255\n",
      "           f       0.00      0.00      0.00       321\n",
      "           g       0.00      0.00      0.00       473\n",
      "           h       0.62      0.58      0.60      1178\n",
      "           i       0.00      0.00      0.00       342\n",
      "           j       0.00      0.00      0.00       261\n",
      "           k       0.00      0.00      0.00       371\n",
      "           l       0.67      0.86      0.75      2001\n",
      "           m       0.00      0.00      0.00       368\n",
      "           n       0.79      0.66      0.72      1524\n",
      "           o       0.00      0.00      0.00       366\n",
      "           p       0.00      0.00      0.00       304\n",
      "           q       0.00      0.00      0.00       404\n",
      "           r       0.62      0.83      0.71      1840\n",
      "           s       0.00      0.00      0.00       339\n",
      "           t       0.47      0.59      0.53      2401\n",
      "           u       0.00      0.00      0.00       387\n",
      "           v       0.00      0.00      0.00       374\n",
      "           w       0.00      0.00      0.00       391\n",
      "           x       0.18      0.47      0.26       381\n",
      "           y       0.00      0.00      0.00       303\n",
      "           z       0.00      0.00      0.00       365\n",
      "\n",
      "    accuracy                           0.53     21647\n",
      "   macro avg       0.19      0.26      0.21     21647\n",
      "weighted avg       0.41      0.53      0.46     21647\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.38      0.65      0.48       313\n",
      "           b       0.21      0.43      0.28       164\n",
      "           c       0.00      0.00      0.00        78\n",
      "           d       0.38      0.67      0.48       359\n",
      "           e       0.69      0.86      0.77       837\n",
      "           f       0.00      0.00      0.00        79\n",
      "           g       0.00      0.00      0.00       116\n",
      "           h       0.58      0.55      0.57       301\n",
      "           i       0.00      0.00      0.00        85\n",
      "           j       0.00      0.00      0.00        56\n",
      "           k       0.00      0.00      0.00        95\n",
      "           l       0.69      0.88      0.77       534\n",
      "           m       0.00      0.00      0.00        96\n",
      "           n       0.78      0.62      0.69       374\n",
      "           o       0.00      0.00      0.00       100\n",
      "           p       0.00      0.00      0.00        64\n",
      "           q       0.00      0.00      0.00       101\n",
      "           r       0.63      0.84      0.72       480\n",
      "           s       0.00      0.00      0.00        98\n",
      "           t       0.47      0.60      0.52       564\n",
      "           u       0.00      0.00      0.00        95\n",
      "           v       0.00      0.00      0.00        94\n",
      "           w       0.00      0.00      0.00        76\n",
      "           x       0.17      0.44      0.24        89\n",
      "           y       0.00      0.00      0.00        78\n",
      "           z       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.53      5412\n",
      "   macro avg       0.19      0.25      0.21      5412\n",
      "weighted avg       0.42      0.53      0.46      5412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "params={'random_state':0,'max_depth':4}\n",
    "classifier = DecisionTreeClassifier(**params)\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numbers (0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_numbers = data[data['e'] < 10]\n",
    "\n",
    "X = df_numbers.drop(columns = ['e'])\n",
    "y = df_numbers['e']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "labels = np.sort(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      4688\n",
      "         1.0       0.96      1.00      0.98      5046\n",
      "         2.0       0.99      0.98      0.98      4659\n",
      "         3.0       0.97      0.99      0.98      4736\n",
      "         4.0       0.98      0.97      0.98      4485\n",
      "         5.0       0.99      0.98      0.98      4140\n",
      "         6.0       0.99      0.99      0.99      4576\n",
      "         7.0       0.97      0.98      0.98      4920\n",
      "         8.0       1.00      0.95      0.97      4535\n",
      "         9.0       0.98      0.97      0.97      4549\n",
      "\n",
      "    accuracy                           0.98     46334\n",
      "   macro avg       0.98      0.98      0.98     46334\n",
      "weighted avg       0.98      0.98      0.98     46334\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      1090\n",
      "         1.0       0.94      1.00      0.97      1284\n",
      "         2.0       0.99      0.96      0.97      1210\n",
      "         3.0       0.96      0.98      0.97      1233\n",
      "         4.0       0.98      0.96      0.97      1134\n",
      "         5.0       0.98      0.96      0.97      1050\n",
      "         6.0       0.98      0.99      0.98      1129\n",
      "         7.0       0.95      0.98      0.97      1219\n",
      "         8.0       0.99      0.93      0.96      1098\n",
      "         9.0       0.96      0.96      0.96      1137\n",
      "\n",
      "    accuracy                           0.97     11584\n",
      "   macro avg       0.97      0.97      0.97     11584\n",
      "weighted avg       0.97      0.97      0.97     11584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K neighbor\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4688\n",
      "         1.0       0.99      0.99      0.99      5046\n",
      "         2.0       0.99      0.99      0.99      4659\n",
      "         3.0       0.96      0.98      0.97      4736\n",
      "         4.0       0.99      0.99      0.99      4485\n",
      "         5.0       0.97      0.95      0.96      4140\n",
      "         6.0       1.00      1.00      1.00      4576\n",
      "         7.0       0.99      0.97      0.98      4920\n",
      "         8.0       0.96      0.95      0.96      4535\n",
      "         9.0       0.96      0.98      0.97      4549\n",
      "\n",
      "    accuracy                           0.98     46334\n",
      "   macro avg       0.98      0.98      0.98     46334\n",
      "weighted avg       0.98      0.98      0.98     46334\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95      1090\n",
      "         1.0       0.94      0.96      0.95      1284\n",
      "         2.0       0.93      0.91      0.92      1210\n",
      "         3.0       0.89      0.91      0.90      1233\n",
      "         4.0       0.93      0.91      0.92      1134\n",
      "         5.0       0.87      0.84      0.86      1050\n",
      "         6.0       0.97      0.96      0.96      1129\n",
      "         7.0       0.96      0.91      0.94      1219\n",
      "         8.0       0.83      0.86      0.84      1098\n",
      "         9.0       0.87      0.92      0.89      1137\n",
      "\n",
      "    accuracy                           0.91     11584\n",
      "   macro avg       0.91      0.91      0.91     11584\n",
      "weighted avg       0.91      0.91      0.91     11584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OnevsOne\n",
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0,max_iter=4000))\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.90      4688\n",
      "         1.0       0.81      0.97      0.88      5046\n",
      "         2.0       0.91      0.81      0.86      4659\n",
      "         3.0       0.85      0.80      0.83      4736\n",
      "         4.0       0.87      0.87      0.87      4485\n",
      "         5.0       0.92      0.70      0.79      4140\n",
      "         6.0       0.82      0.89      0.85      4576\n",
      "         7.0       0.83      0.83      0.83      4920\n",
      "         8.0       0.81      0.60      0.69      4535\n",
      "         9.0       0.66      0.85      0.75      4549\n",
      "\n",
      "    accuracy                           0.83     46334\n",
      "   macro avg       0.84      0.83      0.82     46334\n",
      "weighted avg       0.84      0.83      0.83     46334\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.91      0.89      1090\n",
      "         1.0       0.82      0.97      0.89      1284\n",
      "         2.0       0.90      0.81      0.86      1210\n",
      "         3.0       0.85      0.81      0.83      1233\n",
      "         4.0       0.88      0.87      0.87      1134\n",
      "         5.0       0.94      0.68      0.79      1050\n",
      "         6.0       0.80      0.89      0.84      1129\n",
      "         7.0       0.85      0.85      0.85      1219\n",
      "         8.0       0.79      0.59      0.68      1098\n",
      "         9.0       0.67      0.86      0.76      1137\n",
      "\n",
      "    accuracy                           0.83     11584\n",
      "   macro avg       0.84      0.83      0.82     11584\n",
      "weighted avg       0.84      0.83      0.83     11584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "classifier= RandomForestClassifier(n_estimators=100,max_depth=4, random_state=0)\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Training dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.72      0.82      4688\n",
      "         1.0       0.83      0.90      0.87      5046\n",
      "         2.0       0.83      0.61      0.70      4659\n",
      "         3.0       0.68      0.53      0.60      4736\n",
      "         4.0       0.84      0.67      0.74      4485\n",
      "         5.0       0.45      0.74      0.56      4140\n",
      "         6.0       0.49      0.76      0.60      4576\n",
      "         7.0       0.78      0.75      0.77      4920\n",
      "         8.0       0.36      0.24      0.29      4535\n",
      "         9.0       0.64      0.70      0.67      4549\n",
      "\n",
      "    accuracy                           0.67     46334\n",
      "   macro avg       0.69      0.66      0.66     46334\n",
      "weighted avg       0.69      0.67      0.67     46334\n",
      "\n",
      "\n",
      "****************************************\n",
      "\n",
      " Classifier performance on Testing dataset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.70      0.79      1090\n",
      "         1.0       0.83      0.90      0.87      1284\n",
      "         2.0       0.82      0.58      0.68      1210\n",
      "         3.0       0.69      0.55      0.61      1233\n",
      "         4.0       0.86      0.66      0.74      1134\n",
      "         5.0       0.44      0.73      0.55      1050\n",
      "         6.0       0.48      0.76      0.59      1129\n",
      "         7.0       0.77      0.74      0.76      1219\n",
      "         8.0       0.33      0.23      0.27      1098\n",
      "         9.0       0.65      0.69      0.67      1137\n",
      "\n",
      "    accuracy                           0.66     11584\n",
      "   macro avg       0.68      0.65      0.65     11584\n",
      "weighted avg       0.68      0.66      0.66     11584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "params={'random_state':0,'max_depth':4}\n",
    "classifier = DecisionTreeClassifier(**params)\n",
    "run_classifier(classifier, X_train, X_test, y_train, y_test, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## Upper Case Letters\n",
    "Rankings of the best classification methods (best to worst):\n",
    "1. K- Neighbors Classifier (also the longest to run, ~30 minutes)\n",
    "2. OnevsOne (got 100% on the training set)\n",
    "3. Random Forest\n",
    "4. Decision Tree\n",
    "\n",
    "## Lower Case Letters\n",
    "1. K- Neighbors Classifier (also the longest to run, ~20 minutes)\n",
    "2. OnevsOne (scored almost 100% on the training set)\n",
    "3. Random Forest\n",
    "4. Decision Tree\n",
    "\n",
    "## Numbers (0-9)\n",
    "This one had the best overall results\n",
    "1. K- Neighbors Classifier (also the longest to run, over an hour)\n",
    "2. OnevsOne (scored almost 100% on the training set)\n",
    "3. Random Forest\n",
    "4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
